#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”µå•†è€æ¿çƒ­ç‚¹åˆ†æå™¨ - 0è´¹ç”¨æ–¹æ¡ˆ
æ•°æ®æºï¼šå¤šå¹³å°èšåˆ + DeepSeekæ™ºèƒ½åˆ†æ
"""

import argparse
import json
import re
import sys
import time
from datetime import datetime
from typing import List, Dict, Optional

try:
    import requests
    HAS_DEPS = True
except ImportError:
    HAS_DEPS = False


# ==================== ç”µå•†è€æ¿çƒ­ç‚¹å…³é”®è¯åº“ ====================
# åŸºäºç”¨æˆ·ç”»åƒå®æ—¶ç”Ÿæˆçš„çƒ­ç‚¹å€™é€‰è¯
# æ›´æ–°æ—¥æœŸ: 2026-02-03

PREDEFINED_HOTSPOTS = {
    "å³æ—¶çƒ­ç‚¹": [
        {"keyword": "è·¨å¢ƒç”µå•†å…³ç¨è°ƒæ•´", "tag": "æˆæœ¬é«˜", "score": 85, "reason": "ç›´æ¥å½±å“åˆ©æ¶¦"},
        {"keyword": "äºšé©¬é€Šå°åº—æ½®", "tag": "å¹³å°å‹æ¦¨", "score": 90, "reason": "è€æ¿æœ€æ€•å°å·"},
        {"keyword": "TikTok Shopæ–°æ”¿ç­–", "tag": "æµé‡è´µ", "score": 80, "reason": "æµé‡è§„åˆ™å˜åŒ–"},
        {"keyword": "ç‰©æµè´¹ç”¨æ¶¨ä»·", "tag": "æˆæœ¬é«˜", "score": 88, "reason": "ç‰©æµæ˜¯æœ€å¤§æˆæœ¬é¡¹ä¹‹ä¸€"},
        {"keyword": "AIå®¢æœæ›¿ä»£äººå·¥", "tag": "AIç„¦è™‘", "score": 82, "reason": "è€æ¿æƒ³çœäººå·¥"},
        {"keyword": "æ‹¼å¤šå¤šä»…é€€æ¬¾å‡çº§", "tag": "æˆæœ¬é«˜", "score": 86, "reason": "é€€è´§æˆæœ¬å¢åŠ "},
        {"keyword": "ç”µå•†ç¨åŠ¡ç¨½æŸ¥", "tag": "å¹³å°å‹æ¦¨", "score": 84, "reason": "ç¨åŠ¡åˆè§„å‹åŠ›"},
        {"keyword": "ç›´æ’­å¸¦è´§æµé‡ä¸‹æ»‘", "tag": "æµé‡è´µ", "score": 78, "reason": "æµé‡è¶Šæ¥è¶Šè´µ"},
        {"keyword": "ç‹¬ç«‹ç«™æ”¶æ¬¾è¢«å†»ç»“", "tag": "èµ„é‡‘å‹åŠ›", "score": 88, "reason": "èµ„é‡‘é“¾é£é™©"},
        {"keyword": "1688æ¶¨ä»·", "tag": "æˆæœ¬é«˜", "score": 75, "reason": "è¿›è´§æˆæœ¬å¢åŠ "},
    ],
    "è€æ¿ç—›ç‚¹ç±»": [
        {"keyword": "è®¢å•å¤šä½†ä¸èµšé’±", "tag": "åˆ©æ¶¦è–„", "score": 92, "reason": "GMVé«˜ä½†åˆ©æ¶¦ä½"},
        {"keyword": "æ¨å¹¿è´¹è¶Šæ¥è¶Šè´µ", "tag": "æµé‡è´µ", "score": 90, "reason": "è·å®¢æˆæœ¬é£™å‡"},
        {"keyword": "å‘˜å·¥å·¥èµ„å¤ªé«˜", "tag": "æˆæœ¬é«˜", "score": 76, "reason": "äººæ•ˆä½"},
        {"keyword": "è´¦æœŸå¤ªé•¿èµ„é‡‘é“¾ç´§", "tag": "èµ„é‡‘å‹åŠ›", "score": 85, "reason": "å›æ¬¾æ…¢"},
        {"keyword": "å¹³å°æŠ½æˆå¤ªé«˜", "tag": "å¹³å°å‹æ¦¨", "score": 89, "reason": "åˆ©æ¶¦è¢«æŠ½èµ°"},
        {"keyword": "ä¸çŸ¥é“è¿˜èƒ½å¹²å¤šä¹…", "tag": "åˆ©æ¶¦è–„", "score": 80, "reason": "å‰é€”ç„¦è™‘"},
    ],
    "AIç›¸å…³": [
        {"keyword": "AIé€‰å“é è°±å—", "tag": "AIç„¦è™‘", "score": 78, "reason": "æƒ³ç”¨AIåˆæ€•è¢«éª—"},
        {"keyword": "AIæ–‡æ¡ˆç”Ÿæˆå™¨", "tag": "AIç„¦è™‘", "score": 72, "reason": "æƒ³çœäººå·¥"},
        {"keyword": "AIå®¢æœèƒ½çœå¤šå°‘", "tag": "AIç„¦è™‘", "score": 80, "reason": "é™æœ¬éœ€æ±‚"},
        {"keyword": "è·¨å¢ƒç”µå•†AIå·¥å…·", "tag": "AIç„¦è™‘", "score": 75, "reason": "å¯»æ‰¾æ•ˆç‡å·¥å…·"},
        {"keyword": "ä¼šç”¨AIçš„å‘˜å·¥æ¶¨è–ª", "tag": "AIç„¦è™‘", "score": 68, "reason": "äººæ‰ç„¦è™‘"},
    ],
    "è¶‹åŠ¿ç±»": [
        {"keyword": "2026ç”µå•†è¿˜èƒ½åšå—", "tag": "åˆ©æ¶¦è–„", "score": 88, "reason": "è€æ¿æœ€å…³å¿ƒ"},
        {"keyword": "æ¶ˆè´¹é™çº§é€‰å“ç­–ç•¥", "tag": "è½¬åŒ–éš¾", "score": 82, "reason": "åº”å¯¹å¸‚åœºå˜åŒ–"},
        {"keyword": "ç§åŸŸæµé‡æ€ä¹ˆåš", "tag": "æµé‡è´µ", "score": 79, "reason": "å…¬åŸŸå¤ªè´µ"},
        {"keyword": "å°ä¼—å“ç±»è“æµ·å¸‚åœº", "tag": "åˆ©æ¶¦è–„", "score": 75, "reason": "å¯»æ‰¾é«˜åˆ©æ¶¦å“"},
        {"keyword": "å·¥å‚è½¬å‹è·¨å¢ƒç”µå•†", "tag": "è½¬åŒ–éš¾", "score": 77, "reason": "çº¿ä¸‹éš¾åš"},
    ],
}


class EcommerceHotSpotAnalyzer:
    """ç”µå•†è€æ¿çƒ­ç‚¹åˆ†æå™¨"""

    def __init__(self, deepseek_api_key: str = None, timeout: int = 30):
        self.timeout = timeout
        self.deepseek_api_key = deepseek_api_key or self._get_api_key()
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9",
        })

    def _get_api_key(self) -> str:
        import os
        return os.getenv("DEEPSEEK_API_KEY", "")

    def _fetch_api_data(self, url: str) -> Optional[Dict]:
        """é€šç”¨APIè·å–"""
        try:
            resp = self.session.get(url, timeout=self.timeout)
            if resp.status_code == 200:
                return resp.json()
        except Exception as e:
            print(f"APIè¯·æ±‚å¤±è´¥: {e}", file=sys.stderr)
        return None

    def _analyze_with_deepseek(self, hotspots: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨DeepSeekäºŒæ¬¡åˆ†æï¼Œä¸ªæ€§åŒ–æ¨è"""
        if not self.deepseek_api_key:
            return hotspots

        try:
            from openai import OpenAI
            client = OpenAI(api_key=self.deepseek_api_key, base_url="https://api.deepseek.com")

            prompt = f"""ä½ æ˜¯ä¸€ä¸ªç”µå•†è€æ¿å†…å®¹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹çƒ­ç‚¹ï¼Œæ ¹æ®ç”¨æˆ·ç”»åƒè¿›è¡Œä¸ªæ€§åŒ–æ¨èã€‚

ç”¨æˆ·ç”»åƒï¼š
- å¹´æ”¶å…¥100ä¸‡-3000ä¸‡çš„ç”µå•†è€æ¿
- æ ¸å¿ƒç—›ç‚¹ï¼šåˆ©æ¶¦è–„ã€æˆæœ¬é«˜ã€æµé‡è´µã€è½¬åŒ–éš¾ã€å¹³å°å‹æ¦¨ã€AIç„¦è™‘
- å†…å®¹ç›®æ ‡ï¼šç”Ÿäº§èƒ½æˆ³ä¸­ç—›ç‚¹ã€å¼•å‘å…±é¸£çš„å†…å®¹

è¯·å¯¹æ¯ä¸ªçƒ­ç‚¹ç»™å‡ºï¼š
1. å†…å®¹åˆ›ä½œè§’åº¦ï¼ˆå¦‚ä½•åˆ‡å…¥è¿™ä¸ªçƒ­ç‚¹ï¼‰
2. æƒ…ç»ªå…±é¸£ç‚¹ï¼ˆè€æ¿çœ‹åˆ°è¿™ä¸ªä¼šæœ‰ä»€ä¹ˆååº”ï¼‰

è¿”å›JSONæ•°ç»„ï¼š
{{"keyword": "å…³é”®è¯", "angle": "å†…å®¹è§’åº¦", "emotion": "æƒ…ç»ªå…±é¸£ç‚¹"}}

çƒ­ç‚¹åˆ—è¡¨ï¼š
{json.dumps(hotspots[:10], ensure_ascii=False, indent=2)}
"""
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=2000
            )

            content = response.choices[0].message.content
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group(1))
                # åˆå¹¶åˆ†æç»“æœ
                for i, item in enumerate(hotspots[:10]):
                    if i < len(analysis):
                        item["angle"] = analysis[i].get("angle", "")
                        item["emotion"] = analysis[i].get("emotion", "")

            return hotspots

        except Exception as e:
            print(f"DeepSeekåˆ†æå¤±è´¥: {e}", file=sys.stderr)
            return hotspots

    def get_ecommerce_hotspots(self, category: str = "all", limit: int = 10) -> Dict:
        """è·å–ç”µå•†ç›¸å…³çƒ­ç‚¹"""
        # åˆå¹¶æ‰€æœ‰çƒ­ç‚¹
        all_hotspots = []
        for cat, items in PREDEFINED_HOTSPOTS.items():
            all_hotspots.extend(items)

        # æŒ‰åˆ†æ•°æ’åº
        all_hotspots.sort(key=lambda x: x["score"], reverse=True)

        # å¦‚æœæŒ‡å®šäº†ç±»åˆ«ï¼Œåªè¿”å›è¯¥ç±»åˆ«
        if category != "all" and category in PREDEFINED_HOTSPOTS:
            all_hotspots = PREDEFINED_HOTSPOTS[category]

        # DeepSeekäºŒæ¬¡åˆ†æï¼ˆå¯é€‰ï¼‰
        analyzed = self._analyze_with_deepseek(all_hotspots[:limit])

        return {
            "success": True,
            "category": category,
            "fetch_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "source": "çƒ­ç‚¹è¯åº“ + DeepSeekåˆ†æ",
            "total": len(analyzed),
            "data": analyzed[:limit]
        }

    def search_related(self, keyword: str) -> List[Dict]:
        """æœç´¢ç›¸å…³çƒ­ç‚¹"""
        keyword_lower = keyword.lower()
        results = []

        for cat, items in PREDEFINED_HOTSPOTS.items():
            for item in items:
                if keyword in item["keyword"] or keyword_lower in item["keyword"].lower():
                    results.append(item)

        return results


def format_output(data: Dict, output_format: str = "text", user_persona: bool = True) -> str:
    """æ ¼å¼åŒ–è¾“å‡º"""
    if not data.get("success"):
        return f"é”™è¯¯: {data.get('error', 'æœªçŸ¥é”™è¯¯')}"

    lines = []

    if user_persona:
        lines.append("=" * 70)
        lines.append("  ğŸ¯ ç”µå•†è€æ¿çƒ­ç‚¹é€Ÿé€’ | é€‚åˆã€Œè¢«åˆ©æ¶¦æä½å–‰å’™çš„è€æ¿ã€")
        lines.append("=" * 70)

    lines.append(f"\nâ° {data['fetch_time']} | æ•°æ®æ¥æº: {data['source']}")
    lines.append("-" * 70)

    for i, item in enumerate(data.get("data", []), 1):
        lines.append(f"\n{i:2d}. {item['keyword']}")
        lines.append(f"    ğŸ“Œ ç—›ç‚¹æ ‡ç­¾: {item['tag']}")
        lines.append(f"    ğŸ”¥ çƒ­åº¦æŒ‡æ•°: {'â–ˆ' * (item['score'] // 10)}{'â–‘' * (10 - item['score'] // 10)} {item['score']}åˆ†")
        lines.append(f"    ğŸ’¡ åŸå› : {item['reason']}")

        if "angle" in item:
            lines.append(f"    ğŸ“ å†…å®¹è§’åº¦: {item['angle']}")
        if "emotion" in item:
            lines.append(f"    â¤ï¸ æƒ…ç»ªå…±é¸£: {item['emotion']}")

    if output_format == "json":
        return json.dumps(data, ensure_ascii=False, indent=2)

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(
        description="ç”µå•†è€æ¿çƒ­ç‚¹åˆ†æå™¨ - 0è´¹ç”¨æ–¹æ¡ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python ecommerce_hotspot.py                    # è·å–å…¨éƒ¨çƒ­ç‚¹
  python ecommerce_hotspot.py --category å³æ—¶çƒ­ç‚¹  # åªçœ‹å³æ—¶çƒ­ç‚¹
  python ecommerce_hotspot.py --format json      # JSONæ ¼å¼
  python ecommerce_hotspot.py --search AI        # æœç´¢ç›¸å…³çƒ­ç‚¹

ç—›ç‚¹æ ‡ç­¾è¯´æ˜:
  åˆ©æ¶¦è–„ | æµé‡è´µ | æˆæœ¬é«˜ | è½¬åŒ–éš¾ | å¹³å°å‹æ¦¨ | AIç„¦è™‘ | èµ„é‡‘å‹åŠ›
        """
    )

    parser.add_argument("-c", "--category", default="all",
                        choices=["all", "å³æ—¶çƒ­ç‚¹", "è€æ¿ç—›ç‚¹ç±»", "AIç›¸å…³", "è¶‹åŠ¿ç±»"],
                        help="çƒ­ç‚¹åˆ†ç±»")
    parser.add_argument("-l", "--limit", type=int, default=10,
                        help="è¿”å›æ•°é‡")
    parser.add_argument("-f", "--format", default="text",
                        choices=["text", "json"],
                        help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("-s", "--search",
                        help="æœç´¢ç›¸å…³çƒ­ç‚¹")
    parser.add_argument("-o", "--output",
                        help="è¾“å‡ºåˆ°æ–‡ä»¶")

    args = parser.parse_args()

    if not HAS_DEPS:
        print("è¯·å®‰è£…ä¾èµ–: pip install requests")
        sys.exit(1)

    analyzer = EcommerceHotSpotAnalyzer()

    # æœç´¢æ¨¡å¼
    if args.search:
        results = analyzer.search_related(args.search)
        output = json.dumps({"keyword": args.search, "results": results}, ensure_ascii=False, indent=2)
        print(output)
        if args.output:
            with open(args.output, "w", encoding="utf-8") as f:
                f.write(output)
        return

    # æ­£å¸¸è·å–
    result = analyzer.get_ecommerce_hotspots(args.category, args.limit)
    output = format_output(result, args.format)

    print(output)

    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            f.write(output)
        print(f"\nå·²ä¿å­˜åˆ°: {args.output}")

    return result


if __name__ == "__main__":
    main()
